% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/haven-stata.R
\name{read_dta}
\alias{read_dta}
\alias{read_stata}
\alias{write_dta}
\title{Read and write Stata DTA files}
\usage{
read_dta(
  file,
  encoding = NULL,
  col_select = NULL,
  skip = 0,
  n_max = Inf,
  .name_repair = "unique"
)

read_stata(
  file,
  encoding = NULL,
  col_select = NULL,
  skip = 0,
  n_max = Inf,
  .name_repair = "unique"
)

write_dta(
  data,
  path,
  version = 14,
  label = attr(data, "label"),
  strl_threshold = 2045,
  adjust_tz = TRUE
)
}
\arguments{
\item{file}{Either a path to a file, a connection, or literal data
(either a single string or a raw vector).

Files ending in \code{.gz}, \code{.bz2}, \code{.xz}, or \code{.zip} will
be automatically uncompressed. Files starting with \verb{http://},
\verb{https://}, \verb{ftp://}, or \verb{ftps://} will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.

Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with \code{I()}, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.

Using a value of \code{\link[readr:clipboard]{clipboard()}} will read from the system clipboard.}

\item{encoding}{The character encoding used for the file. Generally,
only needed for Stata 13 files and earlier. See Encoding section
for details.}

\item{col_select}{One or more selection expressions, like in
\code{\link[dplyr:select]{dplyr::select()}}. Use \code{c()} or \code{list()} to use more than one expression.
See \code{?dplyr::select} for details on available selection options. Only the
specified columns will be read from \code{data_file}.}

\item{skip}{Number of lines to skip before reading data.}

\item{n_max}{Maximum number of lines to read.}

\item{.name_repair}{Treatment of problematic column names:
\itemize{
\item \code{"minimal"}: No name repair or checks, beyond basic existence,
\item \code{"unique"}: Make sure names are unique and not empty,
\item \code{"check_unique"}: (default value), no name repair, but check they are
\code{unique},
\item \code{"universal"}: Make the names \code{unique} and syntactic
\item a function: apply custom name repair (e.g., \code{.name_repair = make.names}
for names in the style of base R).
\item A purrr-style anonymous function, see \code{\link[rlang:as_function]{rlang::as_function()}}
}

This argument is passed on as \code{repair} to \code{\link[vctrs:vec_as_names]{vctrs::vec_as_names()}}.
See there for more details on these terms and the strategies used
to enforce them.}

\item{data}{Data frame to write.}

\item{path}{Path to a file where the data will be written.}

\item{version}{File version to use. Supports versions 8-15.}

\item{label}{Dataset label to use, or \code{NULL}. Defaults to the value stored in
the "label" attribute of \code{data}. Must be <= 80 characters.}

\item{strl_threshold}{Any character vectors with a maximum length greater
than \code{strl_threshold} bytes will be stored as a long string (strL) instead
of a standard string (str#) variable if \code{version} >= 13. This defaults to
2045, the maximum length of str# variables. See the Stata \href{https://www.stata.com/features/overview/long-strings/}{long string}
documentation for more details.}

\item{adjust_tz}{Stata, SPSS and SAS do not have a concept of time zone,
and all \link{date-time} variables are treated as UTC. \code{adjust_tz} controls
how the timezone of date-time values is treated when writing.
\itemize{
\item If \code{TRUE} (the default) the timezone of date-time values is ignored, and
they will display the same in R and Stata/SPSS/SAS, e.g.
\code{"2010-01-01 09:00:00 NZDT"} will be written as \code{"2010-01-01 09:00:00"}.
Note that this changes the underlying numeric data, so use caution if
preserving between-time-point differences is critical.
\item If \code{FALSE}, date-time values are written as the corresponding UTC value,
e.g. \code{"2010-01-01 09:00:00 NZDT"} will be written as
\code{"2009-12-31 20:00:00"}.
}}
}
\value{
A tibble, data frame variant with nice defaults.

Variable labels are stored in the "label" attribute of each variable.
It is not printed on the console, but the RStudio viewer will show it.

If a dataset label is defined in Stata, it will stored in the "label"
attribute of the tibble.

\code{write_dta()} returns the input \code{data} invisibly.
}
\description{
Currently haven can read and write logical, integer, numeric, character
and factors. See \code{\link[=labelled]{labelled()}} for how labelled variables in
Stata are handled in R.

Character vectors will be stored as \code{strL} if any components are
\code{strl_threshold} bytes or longer (and \code{version} >= 13); otherwise they will
be stored as the appropriate \code{str#}.
}
\section{Character encoding}{

Prior to Stata 14, files did not declare a text encoding, and the
default encoding differed across platforms. If \code{encoding = NULL},
haven assumes the encoding is windows-1252, the text encoding used by
Stata on Windows. Unfortunately Stata on Mac and Linux use a different
default encoding, "latin1". If you encounter an error such as
"Unable to convert string to the requested encoding", try
\code{encoding = "latin1"}

For Stata 14 and later, you should not need to manually specify \code{encoding}
value unless the value was incorrectly recorded in the source file.
}

\examples{
path <- system.file("examples", "iris.dta", package = "haven")
read_dta(path)

tmp <- tempfile(fileext = ".dta")
write_dta(mtcars, tmp)
read_dta(tmp)
read_stata(tmp)
}
